# AI Inference Infrastructure â€“ Step 0

## Goal
Bootstrap a reproducible GPU-backed inference service
as a foundation for AI infrastructure experiments.

## Stack
- PyTorch
- vLLM
- FastAPI

## Next Steps
- Add Prometheus metrics
- Add load generator
- Measure p99 latency under concurrency